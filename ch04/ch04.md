Run the container under an alias:

`docker run --name <NAME> <CONTAINER>`

---
Rename the container:

`docker rename <NEW_NAME> <OLD_NAME>`

---
Also, inspect it with:

for logs: `docker logs <CONTAINER>`

for more details: `docker inspect <CONTAINER>` (JSON format)

---
Extract fields from `docker inspect`:

**1st METHOD**: `jq`

For inspecting the JSON you *could* use `grep` or `awk`. 

Better to use `JQ` when it comes to JSONs if you want to inspect the result from the shell.

So, for example:

`docker inspect <CONTIANER> | jq ` will prettify it.

`jq .[0].Created` to get the first element of that array (output of `docker inspect` is an array) and get the `Created` field.

Can use `-r` for the raw value, without colors.

**2nd METHOD**: `--format` 

use Go template expressions.

`docker inspect --format '{{ .Created }}' <CONTAINER_1> <CONTAINER_2>` 

---
You can also label the docker containers you run:

`docker run -label "<LABEL_NAME>=<LABEL>` (or just `-l`)

Also, docker can differentiate between labels if you just leave the `LABEL` tag empty. Therefore, just having a `LABEL_NAME`.

Also, you can filter after the owner with `docker ps --filter label=<LABEL_NAME>=<LABEL>`, for example.

---
Using a shell in the container 

`docker exec` - introduce a process in the container
 
You can use it to get a shell into the container, so for example: `docker exec -ti <CONTAINER_ID> sh`

Or you can see the processes in that container with: `docker exec <CONTAINER_ID> ps`, from outside the container.

* This assumes that the container is running.

---
*Referring to using a sh in a container*;If the container is not running:

We can use `docker export` to transport the whole filesystem of the container.
Like `docker export <CONTAINER_NAME> > <NAME>.tar` and then you can extract that, and 
if you are on a linux system - you can even use `sudo chroot .` to get a shell in that filesystem.

---
Copy a file from the container:

This could prove useful if a container stops immediately after you try to run it.

- You could get inside the files:
`docker cp <CONTAINER_ID>:<PATH_IN_CONTAINER> .`


- Or you could use:
`docker run -ti --entrypoint sh <CONTAINER_NAME>`. Sometimes it works with `sh`, sometimes with `bash`, sometimes not even with that. It depends on the container and if it has a shell installed, really.


- Another thing that might prove useful is using:
`docker diff <CONTAINER_ID>`. That allows us to see which files were added/changed/removed.

---

It's interesting to see the how close **containers** are to **processes**. If you get this, you'll see that containers are closer to 
*fancy processes* rather than *lightweight VM's*. In the end, a process running in a container is, in fact, a process running on the host.

Therefore, if a process is using too much memory:
- swap is used (if available)
- if there is not enough swap space OOM is called
- OOM kills the process
- sometimes it kills an unrelated process as well

This is the same thing that happens with containers on your system. The catch is, the OOM kills processes that reside in that container only if need be.

---
(Memory - incompressible resource)

Limiting memory used by a container:

- `--memory` - which limits the physical RAM.


- `--memory-swap` - which limits the RAM+Swap. 

e.g `--memory  100m` = 100 megabytes. Can use other unit suffix/bytes.

---
(CPU - compressible resource)

Limiting CPU usage:

- `--cpu-shares` - set relative priority (default is 1024). It comes into play when CPU is maxed out and you need to get more CPU cycles.


- `--cpus` - use % of CPU. For example, `--cpus 0.1` uses 10% of one CPU.


- `cpuset-cpus` - on a multi-core machine, you can say that a container runs on a specific CPU.